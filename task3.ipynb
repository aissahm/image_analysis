{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vWazAVEu_ncp",
        "qoURqel3YsZr",
        "Ky5pc75mY1Wr",
        "YLZWtE3X_7zI",
        "rdvcDuw5EvaX",
        "lgHPpHmJGTcm"
      ],
      "authorship_tag": "ABX9TyOE5YHVTKMU9Fao6wZCWru2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aissahm/image_analysis/blob/master/task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSymrW4A_P_6"
      },
      "source": [
        "# **Task 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkcZApPy_J9O"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import segmentation\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWazAVEu_ncp"
      },
      "source": [
        "## **Introduction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPvzBpO2_pWK",
        "outputId": "73299039-4339-4a1b-d127-3cb797850c25"
      },
      "source": [
        "#returns mask for correspoinding image\n",
        "def returnMaskPathFromImagePath(imagePath):\n",
        "  imagePath = imagePath.replace(\" \", \"\")\n",
        "  return imagePath.replace(\"orig\", \"mask\") \n",
        "\n",
        "#given a text file containing the name of training images return pathfile of respective masks\n",
        "def returnMaskImagesPathArray(trainTextPath):\n",
        "  mask_images_path_array = []\n",
        "  train_images_array = []\n",
        "  with open(trainTextPath, 'r') as file:\n",
        "      data = file.read().replace('\\n', ';')\n",
        "      train_images_array = data.split(\";\")\n",
        "  for train_image_str in train_images_array:\n",
        "    mask_image_str = train_image_str.replace(\"./plates/orig\", \"/content/plates/mask\")\n",
        "    if len(mask_image_str) > 0:\n",
        "      mask_images_path_array.append(mask_image_str)\n",
        "\n",
        "  return mask_images_path_array\n",
        "\n",
        "#return the subimage of interest\n",
        "def returnSubimageWith(width, height, xcenter, ycenter, maskImg):\n",
        "  xstart = xcenter - width//2\n",
        "  xend = xcenter + width//2\n",
        "  ystart = ycenter - height//2\n",
        "  yend = ycenter + height//2\n",
        "  return maskImg[ystart:yend+1,xstart: xend+1,:]\n",
        "\n",
        "#returns the number of pixels representing the plate in the mask\n",
        "def returnPlateNumberPixelsFromMask(maskImg):\n",
        "  #maskImg = cv2.imread(maskPath)\n",
        "  return maskImg.sum()/(3*255)\n",
        "\n",
        "#given width x height, and center coordinates of subimage, returns number of plate pixels contained in subimage\n",
        "def returnPlateNumberPixelsCovBySubimage(width, height, xcenter, ycenter, maskImg):\n",
        "  xstart = xcenter - width//2\n",
        "  if xstart < 0:\n",
        "    xstart = 0\n",
        "  xend = xcenter + width//2\n",
        "  ystart = ycenter - height//2\n",
        "  if ystart < 0:\n",
        "    ystart = 0\n",
        "  yend = ycenter + height//2\n",
        "  subImg = maskImg[ystart:yend+1,xstart: xend+1,:]\n",
        "\n",
        "  return subImg.sum()/(3*255)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 23.3 ms (started: 2021-01-02 21:26:58 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoURqel3YsZr"
      },
      "source": [
        "## **Converting original images from Grayscale to YCbCR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZzZRtlA_vHg",
        "outputId": "2accc9f0-3a5b-4612-a020-05d37cc7157a"
      },
      "source": [
        "#function that saves an image\n",
        "def saveImage(image, imagefullpath):\n",
        "  cv2.imwrite(imagefullpath, image)\n",
        "\n",
        "#Mapping from grayscale pixel to RGB using color table\n",
        "def fromGrayscaleToRGBMapping(pixel, H):\n",
        "  V = pixel / H\n",
        "  V = (6 - 2) * V + 1\n",
        "  r_p = H * max(0, (3- abs(V-4) - abs(V-5))/2 )\n",
        "  g_p = H * max(0, (4- abs(V-2) - abs(V-4))/2 )\n",
        "  b_p = H * max(0, (3- abs(V-1) - abs(V-2))/2 )\n",
        "  return [r_p, g_p, b_p]\n",
        "\n",
        "#Transform the grayscale image with one channel into an RGB image with 3 channels\n",
        "def fromGrayscaleToRGB(grayscaleimage, bits):\n",
        "  if len(grayscaleimage.shape) !=2:\n",
        "    print (\"Error: image is not a grayscale image\")\n",
        "    return 0\n",
        "  \n",
        "  H = 2**bits -1\n",
        "\n",
        "  #we initiate an rgb image with 3 channels with same dimensions as grayscale image\n",
        "  rgbimage = np.zeros((grayscaleimage.shape[0], grayscaleimage.shape[1], 3))\n",
        "  i = 0\n",
        "  while i < grayscaleimage.shape[0]:\n",
        "    j = 0\n",
        "    while j < grayscaleimage.shape[1]:\n",
        "      r_p, g_p, b_p = fromGrayscaleToRGBMapping(grayscaleimage[i][j], H)\n",
        "      rgbimage[i][j][0] = r_p\n",
        "      rgbimage[i][j][1] = g_p\n",
        "      rgbimage[i][j][2] = b_p\n",
        "      \n",
        "      j +=1\n",
        "    i +=1\n",
        "  \n",
        "  return rgbimage\n",
        "\n",
        "#Transform an RGB image with 3 channels into a YCbCr image with 3 channels\n",
        "def fromRGBToYCbCr(rgbimage, bits):\n",
        "  conversionMatrix = np.array([[0.299, 0.587, 0.144], [-0.169, -0.331, 0.500], [0.500, -0.419, -0.081]])\n",
        "  bias = np.array([0, 2**(bits - 1), 2**(bits -1)])\n",
        "  YCbCrimage = np.zeros((rgbimage.shape[0], rgbimage.shape[1], rgbimage.shape[2]))\n",
        "\n",
        "  i = 0\n",
        "  while i < rgbimage.shape[0]:\n",
        "    j = 0\n",
        "    while j < rgbimage.shape[1]:\n",
        "      YCbCrimage[i][j] = conversionMatrix @ rgbimage[i][j] + bias\n",
        "      j += 1\n",
        "    i += 1\n",
        "\n",
        "  return YCbCrimage\n",
        "\n",
        "#Main function that converts a grayscale image with 1 channel to a YCbCr image with 3 channels\n",
        "def fromGrayscaleToYCbCr(image, bits):\n",
        "  rgbimage = fromGrayscaleToRGB(image, bits)\n",
        "  if len(rgbimage.shape) < 3:\n",
        "    return 0\n",
        "  return fromRGBToYCbCr(rgbimage, bits)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 58.5 ms (started: 2021-01-02 21:27:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDMGT6LE_zLR"
      },
      "source": [
        "**We create the YCbCr images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIHJps7Q_yfD",
        "outputId": "913b5359-f128-4c11-dddd-d53cd4f8ee8f"
      },
      "source": [
        "directory = '/content/plates/'\n",
        "\n",
        "#creating the folder that will contain the YCbCr images\n",
        "os.mkdir(\"ycbcrplates\")\n",
        "\n",
        "ycbcrdirectory = \"/content/ycbcrplates/\"\n",
        "\n",
        "i = 0 \n",
        "for filename in os.listdir(directory):\n",
        "  if \"orig\" in filename:\n",
        "    grayscaleimg = cv2.imread(directory + filename, cv2.IMREAD_GRAYSCALE)\n",
        "    ycbcrimg = fromGrayscaleToYCbCr(grayscaleimg, 8)\n",
        "    ycbcrimg = ycbcrimg.astype('uint8')\n",
        "\n",
        "    ycbcrimagepath = ycbcrdirectory + filename\n",
        "    cv2.imwrite(ycbcrimagepath, ycbcrimg)\n",
        "    i += 1\n",
        "\n",
        "print(\"Done,\", i, \" images from 'plates/' converted to YCbCr.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done, 200  images from 'plates/' converted to YCbCr.\n",
            "time: 4min 30s (started: 2021-01-02 21:27:23 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky5pc75mY1Wr"
      },
      "source": [
        "## **Converting Images from Grayscale to LAB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YnYsZSYY6Oz"
      },
      "source": [
        "\n",
        "def fromXYZtoLAB(xyzimage):\n",
        "\n",
        "\n",
        "\n",
        "def fromRGBtoXYZMapping(rgbpixel):\n",
        "  xyzpixel = rgbpixel / 255.\n",
        "\n",
        "  if xyzpixel[0] > 0.04045:\n",
        "    xyzpixel[0] = ( ( xyzpixel[0] + 0.055 ) / 1.055 ) ** 2.4\n",
        "  else:\n",
        "    xyzpixel[0] = xyzpixel[0] / 12.92\n",
        "  \n",
        "  if xyzpixel[1] > 0.04045:\n",
        "    xyzpixel[1] = ( ( xyzpixel[1] + 0.055 ) / 1.055 ) ** 2.4\n",
        "  else:  \n",
        "    xyzpixel[1] = xyzpixel[1] / 12.92\n",
        "  \n",
        "  if xyzpixel[2] > 0.04045:\n",
        "    xyzpixel[2] = ( ( xyzpixel[2] + 0.055 ) / 1.055 ) ** 2.4\n",
        "  else:\n",
        "    xyzpixel[2] = xyzpixel[2] / 12.92\n",
        "\n",
        "  return xyzpixel\n",
        "\n",
        "def fromRGBtoXYZ(rgbimage):\n",
        "  #we initiate an XYZ image with 3 channels with same dimensions as RGB image\n",
        "  xyzimage = np.zeros((rgbimage.shape[0], rgbimage.shape[1], rgbimage.shape[2]))\n",
        "  i = 0\n",
        "  while i < rgbimage.shape[0]:\n",
        "    j = 0\n",
        "    while j < rgbimage.shape[1]:\n",
        "      x_p, y_p, z_p = fromRGBtoXYZMapping(rgbimage[i][j])\n",
        "      xyzimage[i][j][0] = x_p\n",
        "      xyzimage[i][j][1] = y_p\n",
        "      xyzimage[i][j][2] = z_p\n",
        "      j +=1\n",
        "    i +=1\n",
        "  \n",
        "  return xyzimage\n",
        "\n",
        "#transforms the image from RGB to LAB\n",
        "def fromRGBToLAB(rgbimage):\n",
        "\n",
        "\n",
        "\n",
        "#Main function that converts a grayscale image with 1 channel to a YCbCr image with 3 channels\n",
        "def fromGrayscaleToLAB(image, bits):\n",
        "  rgbimage = fromGrayscaleToRGB(image, bits)\n",
        "  if len(rgbimage.shape) < 3:\n",
        "    return 0\n",
        "  return fromRGBToLAB(rgbimage, bits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLZWtE3X_7zI"
      },
      "source": [
        "## **Super-pixel segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNHwy_0S__e9",
        "outputId": "000f7b95-7763-450d-93de-3a9683506a9e"
      },
      "source": [
        "#returns the Geo center of each super pixel contained in an image\n",
        "def returnSuperPixelsGeometricCenters(labelimage):\n",
        "  width = labelimage.shape[1]\n",
        "  height = labelimage.shape[0]\n",
        "  nSuperPixels = np.max(labelimage) + 1\n",
        "  plabelCoordinates = np.zeros(nSuperPixels)\n",
        "\n",
        "  xCoordinates = np.zeros(nSuperPixels)\n",
        "  yCoordinates = np.zeros(nSuperPixels)\n",
        "  nElements = np.zeros(nSuperPixels)\n",
        "\n",
        "  i = 0\n",
        "  while i < height:\n",
        "    j = 0\n",
        "    while j < width:\n",
        "      plabel = labelimage[i][j]\n",
        "      xSum = xCoordinates[plabel]\n",
        "      ySum = yCoordinates[plabel]\n",
        "      nLabelElements = nElements[plabel]\n",
        "\n",
        "      xCoordinates[plabel] = xSum + j\n",
        "      yCoordinates[plabel] = ySum + i\n",
        "      nElements[plabel] = nLabelElements + 1  \n",
        "      j += 1\n",
        "    i += 1\n",
        "  \n",
        "  geocenters = []\n",
        "  \n",
        "  plabel = 0\n",
        "  while plabel < nSuperPixels :\n",
        "    xCenter = xCoordinates[plabel] / nElements[plabel]\n",
        "    yCenter = yCoordinates[plabel] / nElements[plabel]\n",
        "    geocenters.append([int(xCenter), int(yCenter)])\n",
        "    plabel += 1\n",
        "  \n",
        "  return geocenters\n",
        "\n",
        "#Perform Superpixel segmentation\n",
        "def returnLabelsWithSuperPixelSegmentation(imagepath, numberSuperpixels):\n",
        "  originalimage = cv2.imread(imagepath)\n",
        "  return segmentation.slic(originalimage, n_segments=numberSuperpixels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 22.7 ms (started: 2021-01-02 21:31:56 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUaYVR-YAH9B",
        "outputId": "7334ad8e-089d-42bc-ff5a-f1794992857e"
      },
      "source": [
        "#Function that loops through the superpixels number until a plate in subimage is found \n",
        "#With threshold \n",
        "def returnMinimumSuperpixelsFor(imagepath, numberSuperpixels, width, height, threshold):\n",
        "  \n",
        "  subimageWithPlateFound = False\n",
        "\n",
        "  maskPath = returnMaskPathFromImagePath(imagepath)\n",
        "  \n",
        "  maskImage = cv2.imread(maskPath)\n",
        "  \n",
        "  nPlatePixelOriginalMask = returnPlateNumberPixelsFromMask(maskImage)\n",
        "  \n",
        "  while subimageWithPlateFound == False:\n",
        "    \n",
        "    labels = returnLabelsWithSuperPixelSegmentation(imagepath, numberSuperpixels)\n",
        "    labelsGeocenters = returnSuperPixelsGeometricCenters(labels)\n",
        "\n",
        "    for labelGeocenter in labelsGeocenters:\n",
        "      xCenter = labelGeocenter[0]\n",
        "      yCenter = labelGeocenter[1]\n",
        "      nPlatePixelsSubimage = returnPlateNumberPixelsCovBySubimage(width, height, xCenter, yCenter, maskImage)\n",
        "      \n",
        "      if nPlatePixelsSubimage / nPlatePixelOriginalMask >= threshold:\n",
        "        subimageWithPlateFound = True\n",
        "        break\n",
        "\n",
        "    if subimageWithPlateFound == False:\n",
        "      numberSuperpixels += 1\n",
        "      \n",
        "    #stopping algorithm if number of superpixels is too high\n",
        "    #then width, height aren't adequate\n",
        "    if numberSuperpixels > 100 and subimageWithPlateFound == False:\n",
        "      numberSuperpixels = -1\n",
        "      break\n",
        "\n",
        "  return numberSuperpixels "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 13 ms (started: 2021-01-02 21:32:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH_gNdodAQCK"
      },
      "source": [
        "In this task 3, we reduce the number of plates pixels required to classify a subimage as class 1 \"plate/foreground\". In the previous tasks (1 and 3), we chose a threshold of 90%. In this task, we set the thresold to 50%. That means that every patch that contains just 50% of the plate pixels inside the patch is classified as a \"plate/foreground\". \n",
        "\n",
        "Note: We will have to take that into account when comparing the results with the classifiers we built in the previous tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B79F4krMAuQO",
        "outputId": "de877bfb-292c-4c7a-9b8c-bacc0b6ad789"
      },
      "source": [
        "w = 100 #175 #163\n",
        "h = 60 #81 #79\n",
        "thresholdV = 0.5"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.77 ms (started: 2021-01-02 21:42:53 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GueLKinvA1Pj"
      },
      "source": [
        "superpixelsStart = 48\n",
        "\n",
        "platesFolderPath = \"/content/plates/\"\n",
        "\n",
        "f = open(\"train1.txt\", \"r\")\n",
        "for imgpath in f:\n",
        "  imgpath = imgpath.replace(\"./plates/\", \"\")\n",
        "  imgpath = imgpath.replace(\" \", \"\")\n",
        "  imgpath = platesFolderPath + imgpath\n",
        "  \n",
        "  if len(imgpath) > 5 and superpixelsStart > 0:\n",
        "    superpixelsStart = returnMinimumSuperpixelsFor(imgpath.strip(), superpixelsStart, w, h, thresholdV)\n",
        "    print(imgpath, \": \", superpixelsStart)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hkD4huoEOjB"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "Since the treshold is very low, we decided to reduce drastically the size of the patches from the previous tasks. This will decrease dramatically the computations required to process the images too. \n",
        "\n",
        "With trials, we found that, with a patch size of 100x60, we require 48 superpixels in order to get at least one patch classified as \"plate/foreground\" for each image in the three training sets. \n",
        "\n",
        "Those parameters will be used in the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdvcDuw5EvaX"
      },
      "source": [
        "## **Creating the subimages with chosen number of superpixels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri6zkDZVFJBb"
      },
      "source": [
        "For the task, we use only the training set 1. We evaluate the classifier and compare it to the classifiers built in the previous tasks. \n",
        "\n",
        "After that, we select which classifier is the best according to the percentage of plate pixels activated and the percentage of pixels outside the plate deactivated. The higher the scores of the two metrics, the better the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVOq1MtTE8lr",
        "outputId": "0aee7cb7-c80f-42cd-8c79-ad851a7752db"
      },
      "source": [
        "def returnSubimageWIth(width, height, xcenter, ycenter, originalimage):\n",
        "  xstart = xcenter - width//2\n",
        "  ystart = ycenter - height//2\n",
        "  xend = xcenter + width//2\n",
        "  yend = ycenter + height//2\n",
        "\n",
        "  if xstart < 0 or ystart < 0:\n",
        "    print(\"xcoord or ycoor negative, xstart =\",  xstart, \", ystart = \", ystart)\n",
        "  \n",
        "  return originalimage[ystart:yend+1,xstart: xend+1,:]\n",
        "\n",
        "#verifiy the subimage fits inside the original image\n",
        "def returnCenterCoordinatesSubimageInsideOrigImage(width, height, xcenter, ycenter, W, H):\n",
        "  if xcenter < width // 2:\n",
        "    xcenter = width // 2\n",
        "    \n",
        "  if xcenter >= W - width//2:\n",
        "    xcenter = W - width//2 - 1\n",
        "\n",
        "  if ycenter < height //2:\n",
        "    ycenter = height //2\n",
        "  \n",
        "  if ycenter >= H - height//2:\n",
        "    ycenter = H - height//2 - 1\n",
        "  \n",
        "  return [xcenter, ycenter]\n",
        "\n",
        "#giving a name for the subimage\n",
        "def returnSubimageFilename(width, height, xcenter, ycenter, subimageclass, imagepath):\n",
        "  subimagefilename = imagepath.replace(\".png\", \"\")\n",
        "  subimagefilename = subimagefilename + \"_\" + str(xcenter) + \"_\" + str(ycenter) + \"_\" + str(width) + \"_\" + str(height) + \"_\" + str (subimageclass) + \".png\"\n",
        "  return subimagefilename\n",
        "\n",
        "#returns the subimage characteristics from its name\n",
        "def returnSubimageDimensionsCenterCoordinates(imagename):\n",
        "  imagename = imagename.replace(\".png\", \"\")\n",
        "  elementsArray = imagename.split(\"_\")\n",
        "  imageID = elementsArray[1]\n",
        "  width = int(elementsArray[4])\n",
        "  height = int(elementsArray[5])\n",
        "  xcenter = int(elementsArray[2])\n",
        "  ycenter = int(elementsArray[3])\n",
        "  imageclass = int(elementsArray[6])\n",
        "  return [imageID, width, height, xcenter, ycenter, imageclass]\n",
        "\n",
        "#returns the class of the subimage depending on the percentage \n",
        "#of pixel plates it contains from the original image\n",
        "def returnSubimageClassWith(nPlatePixelsSubimage, nPlatePixelOriginalMask, platePixelsThreshold):\n",
        "  if nPlatePixelsSubimage / nPlatePixelOriginalMask >= platePixelsThreshold:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "#creates the subimages with a given number of superpixels\n",
        "def createSubimagesWithSuperPixelsSegmentation(originalImageFolder, yCbCrImageFolder, imagename, subImageFolder, numberSuperpixels, width, height, platePixelsThreshold):\n",
        "  imagepath = originalImageFolder + imagename\n",
        "  yCbCrimagepath = yCbCrImageFolder + imagename\n",
        "  label = returnLabelsWithSuperPixelSegmentation(imagepath, numberSuperpixels)\n",
        "  labelsGeocenters = returnSuperPixelsGeometricCenters(label)\n",
        "  \n",
        "  maskPath = returnMaskPathFromImagePath(imagepath)\n",
        "  maskImage = cv2.imread(maskPath)\n",
        "  nPlatePixelOriginalMask = returnPlateNumberPixelsFromMask(maskImage)\n",
        "  yCbCrOriginalImage = cv2.imread(yCbCrimagepath)\n",
        "\n",
        "  nSubimagesCreated = 0\n",
        "\n",
        "  W = maskImage.shape[1]\n",
        "  H = maskImage.shape[0]\n",
        "\n",
        "  subimageWithClass1 = False\n",
        "\n",
        "  for labelGeocenter in labelsGeocenters:\n",
        "    xcenter = labelGeocenter[0]\n",
        "    ycenter = labelGeocenter[1]\n",
        "\n",
        "    #we recenter the subimage if needed to fit intside the original image\n",
        "    #we do that because we need to perform batch norm and we need all subimages with same dimensions\n",
        "    xcenter, ycenter = returnCenterCoordinatesSubimageInsideOrigImage(width, height, xcenter, ycenter, W, H)\n",
        "    nPlatePixelsSubimage = returnPlateNumberPixelsCovBySubimage(width, height, xcenter, ycenter, maskImage)\n",
        "    \n",
        "    #getting the class of the subimage according to the threshold of plate pixels inside it\n",
        "    subimageclass = returnSubimageClassWith(nPlatePixelsSubimage, nPlatePixelOriginalMask, platePixelsThreshold)\n",
        "    \n",
        "    subimage = returnSubimageWIth(width, height, xcenter, ycenter, yCbCrOriginalImage)\n",
        "    subimagefilename = returnSubimageFilename(width, height, xcenter, ycenter, subimageclass, imagename)\n",
        "    #saving the subimage\n",
        "    cv2.imwrite(subImageFolder + subimagefilename, subimage)\n",
        "    nSubimagesCreated += 1\n",
        "\n",
        "    if subimageclass == 1:\n",
        "      subimageWithClass1 = True\n",
        "\n",
        "  #we verifiy we get at least one subimage containing enough plate pixels\n",
        "  if subimageWithClass1 == False:\n",
        "    print(\"No class 1 for \", imagename)\n",
        "\n",
        "  return nSubimagesCreated"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 116 ms (started: 2021-01-02 21:50:06 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPPbcfUnFmES",
        "outputId": "cfba6c7e-1ca5-4cb9-92ad-78da59b8c860"
      },
      "source": [
        "number_superpixels = 48\n",
        "\n",
        "yCbCrPlatesFolder = \"/content/ycbcrplates/\"\n",
        "platesFolderPath = \"/content/plates/\"\n",
        "\n",
        "subimageFoldernameArray = [\"train1\"]\n",
        "traintextfilearray = [\"train1.txt\"]\n",
        "\n",
        "i = 0\n",
        "while i < len(traintextfilearray):\n",
        "  totalSubimagesCreated = 0 \n",
        "  f = open(traintextfilearray[i], \"r\")\n",
        "\n",
        "  os.mkdir(subimageFoldernameArray[i])\n",
        "\n",
        "  for imgname in f:\n",
        "    imgname = imgname.replace(\"./plates/\", \"\")\n",
        "    imgname = imgname.replace(\" \", \"\")\n",
        "\n",
        "    if len(imgname) > 5:\n",
        "      subimagesCreated = createSubimagesWithSuperPixelsSegmentation(platesFolderPath, yCbCrPlatesFolder, imgname.strip(), subimageFoldernameArray[i] + \"/\", number_superpixels, w, h, thresholdV)\n",
        "      totalSubimagesCreated += subimagesCreated \n",
        "\n",
        "  print()\n",
        "  print(traintextfilearray[i])\n",
        "  print(\"Number of subimages created :\", totalSubimagesCreated)\n",
        "  i += 1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train1.txt\n",
            "Number of subimages created : 3166\n",
            "time: 30 s (started: 2021-01-02 21:53:37 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeeAvbd7F80-"
      },
      "source": [
        "We create the subimages for the test set 1 also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyqabyCrGAgi",
        "outputId": "fc07bb44-6948-4901-fa26-eb30c8fdda52"
      },
      "source": [
        "subimageFoldernameArray = [\"test1\"]\n",
        "traintextfilearray = [\"test1.txt\"]\n",
        "\n",
        "i = 0\n",
        "while i < len(traintextfilearray):\n",
        "  totalSubimagesCreated = 0 \n",
        "  f = open(traintextfilearray[i], \"r\")\n",
        "\n",
        "  os.mkdir(subimageFoldernameArray[i])\n",
        "\n",
        "  for imgname in f:\n",
        "    imgname = imgname.replace(\"./plates/\", \"\")\n",
        "    imgname = imgname.replace(\" \", \"\")\n",
        "\n",
        "    if len(imgname) > 5:\n",
        "      subimagesCreated = createSubimagesWithSuperPixelsSegmentation(platesFolderPath, yCbCrPlatesFolder, imgname.strip(), subimageFoldernameArray[i] + \"/\", number_superpixels, w, h, thresholdV)\n",
        "      totalSubimagesCreated += subimagesCreated \n",
        "\n",
        "  print()\n",
        "  print(traintextfilearray[i])\n",
        "  print(\"Number of subimages created :\", totalSubimagesCreated)\n",
        "  i += 1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test1.txt\n",
            "Number of subimages created : 3206\n",
            "time: 29.8 s (started: 2021-01-02 21:54:26 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S81EdW3yGWrc"
      },
      "source": [
        "We created the patches from training set 1 images, and test set 1 images. We are ready for the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQwnp0FLXSpq"
      },
      "source": [
        "**Saving the patches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEa309FOXRIP"
      },
      "source": [
        "!zip -r /content/train1patches.zip /content/train1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcS2QmCXh93"
      },
      "source": [
        "!zip -r /content/test1patches.zip /content/test1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgHPpHmJGTcm"
      },
      "source": [
        "## **Marker selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qhG9_NwGdDv"
      },
      "source": [
        "We select randomly a patch from class \"plate/foreground\" that we will mark.\n",
        "\n",
        "We will conduct the following experiments:\n",
        "\n",
        "*   select one class 1 patch and mark it (we mark only the figures appearing on the plate)\n",
        "*   select one class 1 patch and mark it (we mark the border of the plate)\n",
        "*   select two class 1 patch and mark them according to the best results obtained from the previous two experiments\n",
        "*   select three class 1 patch and mark them according to the best results obtained from the previous two experiments\n",
        "\n",
        "Those experiments will allow us to determine how to best mark a class 1 patch, and see how many marked patches we need to achieve the best results from the classifier.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKkQkidpGVY3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FERNrFqqiihc"
      },
      "source": [
        "## **FLIM algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ez3Cu3Gj1fP"
      },
      "source": [
        "We need to get the zip file of FLIM algorithm from [FLIM repository on Github](https://github.com/LIDS-UNICAMP/FLIM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBRhbiMGjH7u"
      },
      "source": [
        "!unzip \"/content/FLIM-master.zip\"\n",
        "\n",
        "!pip install \"/content/FLIM-master/\"\n",
        "\n",
        "!pip install -r \"/content/FLIM-master/requirements.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x1gz1OjjpHG",
        "outputId": "0e2910c4-e583-498b-8dfc-94dfc4a5af9b"
      },
      "source": [
        "import flim as fl\n",
        "\n",
        "from flim import utils\n",
        "\n",
        "#utils.label_connected_componentes(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.79 ms (started: 2021-01-05 14:48:14 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}